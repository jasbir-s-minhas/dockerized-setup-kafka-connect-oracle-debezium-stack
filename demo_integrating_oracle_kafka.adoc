
Wait for Oracle DB to be up (takes several minutes to instantiate)


Verify that the XStream capture process is running: 

[source,bash]
----
docker exec -it oracle /opt/oracle/scripts/startup/04_check_capture.sh
----

Expected output: 

[source,sql]
----
                                            Session                   XStream
                                             Serial Operating System  Program
XStream Component              Session ID    Number Process ID        Name
------------------------------ ---------- --------- ----------------- -------
DBZXOUT - Apply Reader                  1     40349 60836             AS02
DBZXOUT - Apply Coordinator           380     31272 60834             AP01
DBZXOUT - Propagation Send/Rcv        619     10409 55847             CX02
DBZXOUT - Apply Server                631     17119 60838             AS00
CAP$_DBZXOUT_1 - Capture              750     18993 55845             CP01
----

_If you don't see these running (particularly the `Capture`) then refer to https://github.com/confluentinc/demo-scene/blob/master/no-more-silos-oracle/debezium-xstream-system-output.adoc_

Start the rest of the stack

[source,bash]
----
docker-compose up -d
----

Check that Kafka Connect is running:

[source,bash]
----
bash -c ' \
echo -e "\n\n=============\nWaiting for Kafka Connect to start listening on localhost ‚è≥\n=============\n"
while [ $(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors) -ne 200 ] ; do
  echo -e "\t" $(date) " Kafka Connect listener HTTP state: " $(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors) " (waiting for 200)"
  sleep 5
done
echo -e $(date) "\n\n--------------\n\o/ Kafka Connect is ready! Listener HTTP state: " $(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors) "\n--------------\n"
'
----

Check that required connectors are loaded

[source,bash]
----
curl -s localhost:8083/connector-plugins|jq '.[].class'|egrep 'OracleConnector|JdbcSinkConnector|DatagenConnector'
----

[source,bash]
----
"io.confluent.connect.jdbc.JdbcSourceConnector"
"io.confluent.kafka.connect.datagen.DatagenConnector"
"io.debezium.connector.oracle.OracleConnector"
----


Start sqlplus prompt

[source,bash]
----
docker exec -it oracle bash -c 'sleep 1;rlwrap sqlplus Debezium/dbz@localhost:1521/ORCLPDB1'
----

== Show Oracle table + contents

[source,sql]
----
COL FIRST_NAME FOR A15
COL LAST_NAME FOR A15
COL ID FOR 999
COL CREATE_TS FOR A29
COL UPDATE_TS FOR A29
SET LINESIZE 200
SELECT ID, FIRST_NAME, LAST_NAME, CREATE_TS, UPDATE_TS FROM CUSTOMERS; 
----

[source,sql]
----
  ID FIRST_NAME      LAST_NAME       CREATE_TS                     UPDATE_TS
---- --------------- --------------- ----------------------------- -----------------------------
   1 Rica            Blaisdell       04-DEC-18 08.22.32.933376 PM  04-DEC-18 08.22.32.000000 PM
   2 Ruthie          Brockherst      04-DEC-18 08.22.32.953342 PM  04-DEC-18 08.22.32.000000 PM
   3 Mariejeanne     Cocci           04-DEC-18 08.22.32.965713 PM  04-DEC-18 08.22.32.000000 PM
   4 Hashim          Rumke           04-DEC-18 08.22.32.977417 PM  04-DEC-18 08.22.32.000000 PM
   5 Hansiain        Coda            04-DEC-18 08.22.32.979967 PM  04-DEC-18 08.22.32.000000 PM
----


== Getting the data from Oracle to Kafka

There are two approaches - query-based CDC, and log-based CDC. Let's try both, and examine the differences below. 

=== Query-based CDC (JDBC Source connector)

[source,javascript]
----
curl -i -X PUT -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/source-oracle-jdbc-02/config/ \
    -d '{
            "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
            "connection.url": "jdbc:oracle:thin:@oracle:1521/ORCLPDB1",
            "connection.user":"Debezium",
            "connection.password":"dbz",
            "numeric.mapping":"best_fit",
            "mode":"timestamp",
            "poll.interval.ms":"1000",
            "validate.non.null":"false",
            "table.whitelist":"CUSTOMERS",
            "timestamp.column.name":"UPDATE_TS",
            "topic.prefix":"ora-",
            "transforms": "addTopicSuffix,InsertTopic,InsertSourceDetails,copyFieldToKey,extractValuefromStruct",
            "transforms.InsertTopic.type":"org.apache.kafka.connect.transforms.InsertField$Value",
            "transforms.InsertTopic.topic.field":"messagetopic",
            "transforms.InsertSourceDetails.type":"org.apache.kafka.connect.transforms.InsertField$Value",
            "transforms.InsertSourceDetails.static.field":"messagesource",
            "transforms.InsertSourceDetails.static.value":"JDBC Source Connector from Oracle on asgard",
            "transforms.addTopicSuffix.type":"org.apache.kafka.connect.transforms.RegexRouter",
            "transforms.addTopicSuffix.regex":"(.*)",
            "transforms.addTopicSuffix.replacement":"$1-jdbc-02",
            "transforms.copyFieldToKey.type":"org.apache.kafka.connect.transforms.ValueToKey",
            "transforms.copyFieldToKey.fields":"ID",
            "transforms.extractValuefromStruct.type":"org.apache.kafka.connect.transforms.ExtractField$Key",
            "transforms.extractValuefromStruct.field":"ID"
        }'
----

=== Log-based CDC (Debezium Oracle/XStream connector)

[source,bash]
----
curl -i -X PUT -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/source-oracle-dbz-xstream-00/config \
    -d '{
        "connector.class": "io.debezium.connector.oracle.OracleConnector",
        "key.converter": "io.confluent.connect.avro.AvroConverter",
        "key.converter.schema.registry.url": "http://schema-registry:8081",
        "database.server.name" : "asgard",
        "database.hostname" : "oracle",
        "database.port" : "1521",
        "database.user" : "c##xstrm",
        "database.password" : "xs",
        "database.dbname" : "ORCLCDB",
        "database.pdb.name" : "ORCLPDB1",
        "database.out.server.name" : "dbzxout",
        "database.history.kafka.bootstrap.servers" : "kafka:29092",
        "database.history.kafka.topic": "schema-changes.inventory",
        "include.schema.changes": "true",
        "table.blacklist":"ORCLPDB1.AUDSYS.*"
        }'
----

=== Check the connectors

[source,bash]
----
curl -s "http://localhost:8083/connectors?expand=info&expand=status" | \
       jq '. | to_entries[] | [ .value.info.type, .key, .value.status.connector.state,.value.status.tasks[].state,.value.info.config."connector.class"]|join(":|:")' | \
       column -s : -t| sed 's/\"//g'| sort
----
[source,bash]
----
grep -q "DATABASE IS READY TO USE!" <(docker logs -f oracle)
echo -e "$(date) Installing rlwrap on Oracle container"
docker exec -it -u root oracle bash -c "rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm &&  yum install -y rlwrap"
----

[source,bash]
----
source  |  source-oracle-dbz-xstream-00  |  RUNNING  |  RUNNING  |  io.debezium.connector.oracle.OracleConnector
source  |  source-oracle-jdbc-00         |  RUNNING  |  RUNNING  |  io.confluent.connect.jdbc.JdbcSourceConnector
----

=== Examine the data

Run these two `kafkacat` side by side in separate windows from sqlplus: 

* Query-based CDC data in Kafka: 
+
[source,bash]
----
docker exec kafkacat kafkacat -b kafka:29092 -t ora-CUSTOMERS-jdbc-02 -C -u -q -o-1 -r http://schema-registry:8081 -s key=s -s value=avro -J |jq '.'
----

* Log-based CDC data in Kafka: 
+
[source,bash]
----
docker exec kafkacat kafkacat -b kafka:29092 -t asgard.DEBEZIUM.CUSTOMERS -C -u -q -o-1 -r http://schema-registry:8081 -s key=avro -s value=avro -J | jq '.'
----

Run these commands individually and examine the different payloads that you get for each change type. Note https://issues.redhat.com/projects/DBZ/issues/DBZ-1018[DBZ-1018] which means you might see a lag from the log-based approach (this is an issue with the implementation, not the concept)

* Insert
+
[source,sql]
----
SET AUTOCOMMIT ON;

INSERT INTO CUSTOMERS (FIRST_NAME,LAST_NAME,CLUB_STATUS) VALUES ('Rick','Astley','Bronze');
----

* Update
+
[source,sql]
----
UPDATE CUSTOMERS SET CLUB_STATUS = 'Platinum' where ID=42;
----
+
Note that Debezium output includes the prior state of the record too

* Delete
+
[source,sql]
----
DELETE FROM CUSTOMERS WHERE ID=1;
